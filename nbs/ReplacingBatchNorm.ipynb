{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from components.imports import *\n",
    "from components.lightning import train as _train, LightningModel\n",
    "from components.lightning.telemetry import Callback\n",
    "from components.models import ModelBuilder\n",
    "from components.models.base import basic_model_head\n",
    "from components.metrics import accuracy\n",
    "from components.datasets import imagenette\n",
    "from components.utils import find_all\n",
    "from components.models.resnet import ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme('paper')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the accompanying notebook to the \"Replacing BatchNorm\" blog post. For a full description of the ideas and outcomes of this notebook, please see the article.\n",
    "\n",
    "We cover a few different methods of normalising layers in a neural network:\n",
    "- BatchNorm\n",
    "- Increasing Epsilon\n",
    "- Running BatchNorm\n",
    "- LayerNorm, GroupNorm, InstanceNorm\n",
    "- Initialise to normalise\n",
    "- Weight standardisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " On the imagenette leaderboard, the best result after 5 epochs at 128px is 85%. The networks and the image sizes that we use here are smaller than the ones used on the leaderboard, but we should be able to get a similar result (peaking at 75%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds = imagenette('/home/sara/datasets/imagenette2-160/', 96)\n",
    "sub_val_dl = torch.utils.data.DataLoader(val_ds, batch_size=256, \n",
    "                                         sampler=torch.utils.data.SubsetRandomSampler(np.random.choice(np.arange(len(val_ds)), int(0.05*len(val_ds)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Baseline (No BatchNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Sequential):\n",
    "    def __init__(self, cin, cout, bn=None, act=nn.ReLU):\n",
    "        layers = ([nn.Conv2d(cin, cout, 3, padding=1, stride=2, bias=False), act()] + \n",
    "                  ([] if bn is None else [bn(cout)]))\n",
    "        super().__init__(*layers)\n",
    "    \n",
    "class Network(ModelBuilder):\n",
    "    __name__ = 'SmallCNN'\n",
    "    def __init__(self, bn, categories=10):\n",
    "        conv_params = [(c + [bn]) for c in [\n",
    "            [3,8],[8,16],[16,32],[32,32]\n",
    "        ]]\n",
    "        super().__init__(ConvBlock, conv_params, head=basic_model_head(32, categories))\n",
    "\n",
    "class Baseline(LightningModel):\n",
    "    def __init__(self, hparams, norm_layer, use_resnet=False):\n",
    "        if use_resnet:\n",
    "            model = ResNet(18, 10)\n",
    "            model.__name__ = 'ResNet18'\n",
    "            ms,ps = find_all(model, nn.BatchNorm2d, path=True)\n",
    "            for m,p in zip(ms,ps):\n",
    "                model[p] = nn.Identity() if norm_layer is None else norm_layer(m.num_features)\n",
    "        else: \n",
    "            model = Network(norm_layer)\n",
    "        super().__init__(hparams, model, nn.CrossEntropyLoss(), \n",
    "                         train_ds=train_ds, val_ds=val_ds, metrics=[accuracy])\n",
    "        self.reset()\n",
    "        print(model)\n",
    "    def reset(self):\n",
    "        self.model.apply(init_cnn_)\n",
    "        \n",
    "def init_cnn_(m):\n",
    "    if getattr(m, 'bias', None) is not None:\n",
    "        nn.init.zeros_(m.bias)\n",
    "    if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.ones_(m.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This train function is the core of the testing. We can set the normalisation method, the hyper-params to grid search over, whether to print telemetry, how many runs to do (and display standard deviation for) and whether to use a resnet architecture or a small baseline network (4 conv layers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(normalisation=None, hparams=None, max_epochs=3, telemetry=True, \n",
    "          n_runs=3, use_resnet=False, **kwargs):\n",
    "    hp = {'lr': [1e-2,1e-3], 'bs': [128, 2], 'sched': None}\n",
    "    if hparams is not None: \n",
    "        hp.update(hparams)\n",
    "    network = Baseline(hp, normalisation, use_resnet)\n",
    "    _train(network, max_epochs=max_epochs, save_top_k=0, telemetry=telemetry, \n",
    "           n_runs=n_runs, **kwargs)\n",
    "    network.logger.plot()\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(use_resnet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BatchNorm Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(nn.BatchNorm2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(nn.BatchNorm2d, use_resnet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(lambda x: nn.BatchNorm2d(x, eps=1e-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(lambda x: nn.BatchNorm2d(x, eps=1e-1), use_resnet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running BatchNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This in fact is considered in the WS paper as the BCN layer using estimates of the statistics at training time. They also cite https://arxiv.org/abs/1702.03275 as doing the same idea first. \n",
    "\n",
    "These both don't however use the \"true\" statistics up to that point, instead relying on the moving average of the statistics.\n",
    "\n",
    "Interestingly, I think it is important to note that the gradients of a \"detached\" normalisation and the batch normalisation are very different - and it is this characteristic that seemingly smooths training. If simply normalising the outputs of the network was needed, then the initialise to normalise method described below would perform equally. This interpretation, however, seems to be missing from the BCN part of the WS paper - they say that BN helps remove \"elimination singularities\" and CN (GN) helps stabilise the BN for small batches. \n",
    "\n",
    "This means that the running batch norm updates, in point of fact, are quite different from the BN updates in terms of the gradients propagated. The gradients do not have the smoothing effects of the batch statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunningBatchNorm(nn.Module):\n",
    "    \"\"\"Running Batch Norm layer from fast.ai: \n",
    "    https://github.com/fastai/course-v3/blob/master/nbs/dl2/07_batchnorm.ipynb\n",
    "\n",
    "    Uses the running calculations at training time for batch norm.\n",
    "    \"\"\"\n",
    "    def __init__(self, nf, mom=0.1, eps=1e-5):\n",
    "        super().__init__()\n",
    "        self.mom,self.eps = mom,eps\n",
    "        self.weight = nn.Parameter(torch.ones(nf,1,1))\n",
    "        self.bias = nn.Parameter(torch.zeros(nf,1,1))\n",
    "        self.register_buffer('sums', torch.zeros(1,nf,1,1))\n",
    "        self.register_buffer('sqrs', torch.zeros(1,nf,1,1))\n",
    "        self.register_buffer('batch', torch.tensor(0.))\n",
    "        self.register_buffer('count', torch.tensor(0.))\n",
    "        self.register_buffer('step', torch.tensor(0.))\n",
    "        self.register_buffer('dbias', torch.tensor(0.))\n",
    "\n",
    "    def update_stats(self, x):\n",
    "        bs,nc,*_ = x.shape\n",
    "        self.sums.detach_()\n",
    "        self.sqrs.detach_()\n",
    "        dims = (0,2,3)\n",
    "        s = x.sum(dims, keepdim=True)\n",
    "        ss = (x*x).sum(dims, keepdim=True)\n",
    "        c = self.count.new_tensor(x.numel()/nc)\n",
    "#         mom1 = 1 - (1-self.mom)/math.sqrt(bs-1)\n",
    "        mom1 = 1 - (1-self.mom)/math.sqrt(bs)\n",
    "        self.mom1 = self.dbias.new_tensor(mom1)\n",
    "        self.sums.lerp_(s, self.mom1)\n",
    "        self.sqrs.lerp_(ss, self.mom1)\n",
    "        self.count.lerp_(c, self.mom1)\n",
    "        self.dbias = self.dbias*(1-self.mom1) + self.mom1\n",
    "        self.batch += bs\n",
    "        self.step += 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.training: self.update_stats(x)\n",
    "        sums = self.sums\n",
    "        sqrs = self.sqrs\n",
    "        c = self.count\n",
    "        if self.step<100:\n",
    "            sums = sums / self.dbias\n",
    "            sqrs = sqrs / self.dbias\n",
    "            c    = c    / self.dbias\n",
    "        means = sums/c\n",
    "        vars = (sqrs/c).sub_(means*means)\n",
    "        if bool(self.batch < 20): vars.clamp_min_(0.01)\n",
    "        x = (x-means).div_((vars.add_(self.eps)).sqrt())\n",
    "        return x.mul_(self.weight).add_(self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(RunningBatchNorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(RunningBatchNorm, use_resnet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LayerNorm, GroupNorm, InstanceNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LayerNorm\n",
    "train(lambda x: nn.GroupNorm(1,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LayerNorm\n",
    "train(lambda x: nn.GroupNorm(1,x), use_resnet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GroupNorm Paper defaults to 32 groups.\n",
    "# Try 2/4/8\n",
    "# 4 Seems pretty good for the smallcnn, try larger for resnet\n",
    "n_groups = 4\n",
    "train(lambda x: nn.GroupNorm(n_groups, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GroupNorm 32 groups\n",
    "n_groups = 32\n",
    "train(lambda x: nn.GroupNorm(n_groups, x), use_resnet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Which Part of BN actually Helps\n",
    "\n",
    "The Normalisation or the scaling and biasing parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchScaler2d(nn.Module):\n",
    "    \"\"\"Initialise the weights of a basic broadcast linear layer to normalise the input.\n",
    "    Use the LSUV idea for initialisation.\"\"\"\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(1,channels,1,1))\n",
    "        self.bias = nn.Parameter(torch.zeros(1,channels,1,1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x.mul(self.weight).add(self.bias)\n",
    "    \n",
    "class Normalise(nn.Module):\n",
    "    def __init__(self, c, detach=False):\n",
    "        super().__init__()\n",
    "        self.register_buffer('running_mean', torch.zeros(1,c,1,1))\n",
    "        self.register_buffer('running_var', torch.ones(1,c,1,1))\n",
    "        self.d = detach\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "            var,mean = torch.var_mean(x, dim=(0,2,3), keepdim=True)\n",
    "            if self.d: var,mean = var.detach(),mean.detach()\n",
    "            with torch.no_grad():\n",
    "                self.running_mean.lerp_(mean, 0.1)\n",
    "                self.running_var.lerp_(var, 0.1)\n",
    "        else:\n",
    "            var,mean = self.running_var,self.running_mean\n",
    "        return x.sub(mean).div_((var+1e-5).sqrt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ProbBatchScaler2d should use resnet since the small network is pretty klein\n",
    "train(BatchScaler2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(Normalise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Without gradient propagation\n",
    "train(lambda x: Normalise(x, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-4\n",
    "\n",
    "def ws(weight):\n",
    "    mu = weight.mean((1,2,3), keepdim=True)\n",
    "    fin,fout = nn.init._calculate_fan_in_and_fan_out(weight)\n",
    "    kaiming = math.sqrt(2)/math.sqrt(fin)\n",
    "    std = torch.sqrt(weight.var((1,2,3), keepdim=True)+eps)\n",
    "    return weight.sub(mu).div(std) #.mul(kaiming)\n",
    "\n",
    "class WSConv(nn.Conv2d):\n",
    "    def forward(self, input):\n",
    "        return self._conv_forward(input, ws(self.weight))\n",
    "\n",
    "class ConvBlock(nn.Sequential):\n",
    "    def __init__(self, cin, cout, bn=None, act=nn.ReLU):\n",
    "        layers = ([WSConv(cin, cout, 3, padding=1, stride=2, bias=False), act()] + \n",
    "                  ([] if bn is None else [bn(cout)]))\n",
    "        super().__init__(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# WS with GN\n",
    "n_groups = 4\n",
    "train(lambda x: nn.GroupNorm(n_groups, x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WS with GN\n",
    "n_groups = 32\n",
    "nn.Conv2d = WSConv\n",
    "train(lambda x: nn.GroupNorm(n_groups, x), use_resnet=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Channel Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From author implementation: https://github.com/joe-siyuan-qiao/Batch-Channel-Normalization\n",
    "class BCNorm(nn.Module):\n",
    "\n",
    "    def __init__(self, num_channels, num_groups, eps, estimate=True):\n",
    "        super(BCNorm, self).__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.num_groups = num_groups\n",
    "        self.eps = eps\n",
    "        self.weight = nn.Parameter(torch.ones(1, num_groups, 1))\n",
    "        self.bias = nn.Parameter(torch.zeros(1, num_groups, 1))\n",
    "        if estimate:\n",
    "            self.bn = EstBN(num_channels)\n",
    "        else:\n",
    "            self.bn = nn.BatchNorm2d(num_channels)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        out = self.bn(inp)\n",
    "        out = out.view(1, inp.size(0) * self.num_groups, -1)\n",
    "        out = torch.batch_norm(out, None, None, None, None, True, 0, self.eps, True)\n",
    "        out = out.view(inp.size(0), self.num_groups, -1)\n",
    "        out = self.weight * out + self.bias\n",
    "        out = out.view_as(inp)\n",
    "        return out\n",
    "\n",
    "class EstBN(nn.Module):\n",
    "\n",
    "    def __init__(self, num_features):\n",
    "        super(EstBN, self).__init__()\n",
    "        self.num_features = num_features\n",
    "        self.weight = nn.Parameter(torch.ones(num_features))\n",
    "        self.bias = nn.Parameter(torch.zeros(num_features))\n",
    "        self.register_buffer('running_mean', torch.zeros(num_features))\n",
    "        self.register_buffer('running_var', torch.ones(num_features))\n",
    "        self.register_buffer('num_batches_tracked', torch.tensor(0, dtype=torch.long))\n",
    "        self.register_buffer('estbn_moving_speed', torch.zeros(1))\n",
    "\n",
    "    def forward(self, inp):\n",
    "        ms = self.estbn_moving_speed.item()\n",
    "        if self.training:\n",
    "            with torch.no_grad():\n",
    "                inp_t = inp.transpose(0, 1).contiguous().view(self.num_features, -1)\n",
    "                running_mean = inp_t.mean(dim=1)\n",
    "                inp_t = inp_t - self.running_mean.view(-1, 1)\n",
    "                running_var = torch.mean(inp_t * inp_t, dim=1)\n",
    "                self.running_mean.data.mul_(1 - ms).add_(ms * running_mean.data)\n",
    "                self.running_var.data.mul_(1 - ms).add_(ms * running_var.data)\n",
    "        out = inp - self.running_mean.view(1, -1, 1, 1)\n",
    "        out = out / torch.sqrt(self.running_var + 1e-5).view(1, -1, 1, 1)\n",
    "        weight = self.weight.view(1, -1, 1, 1)\n",
    "        bias = self.bias.view(1, -1, 1, 1)\n",
    "        out = weight * out + bias\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCN(nn.Module):\n",
    "    def __init__(self, c, groups):\n",
    "        super().__init__()\n",
    "        assert float(c//groups) == c/groups\n",
    "        self.bn = RunningBatchNorm(c)\n",
    "#         self.bn = nn.BatchNorm2d(c) # Basically change this to RunningBN (or adapt to a moving average version)\n",
    "        self.cn = nn.GroupNorm(groups, c)\n",
    "    def forward(self, x):\n",
    "        return self.cn(self.bn(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(lambda x: BCNorm(x, 4, 1e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Conv2d = WSConv\n",
    "train(lambda x: BCNorm(x, 32, 1e-5), use_resnet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(lambda x: BCN(x, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://github.com/tomgoldstein/loss-landscape\n",
    "\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from scipy.sparse.linalg import LinearOperator, eigsh\n",
    "\n",
    "################################################################################\n",
    "#                              Supporting Functions\n",
    "################################################################################\n",
    "def npvec_to_tensorlist(vec, params):\n",
    "    \"\"\" Convert a numpy vector to a list of tensor with the same dimensions as params\n",
    "\n",
    "        Args:\n",
    "            vec: a 1D numpy vector\n",
    "            params: a list of parameters from net\n",
    "\n",
    "        Returns:\n",
    "            rval: a list of tensors with the same shape as params\n",
    "    \"\"\"\n",
    "    loc = 0\n",
    "    rval = []\n",
    "    for p in params:\n",
    "        numel = p.data.numel()\n",
    "        rval.append(torch.from_numpy(vec[loc:loc+numel]).view(p.data.shape).float())\n",
    "        loc += numel\n",
    "    assert loc == vec.size, 'The vector has more elements than the net has parameters'\n",
    "    return rval\n",
    "\n",
    "\n",
    "def gradtensor_to_npvec(net, include_bn=False):\n",
    "    \"\"\" Extract gradients from net, and return a concatenated numpy vector.\n",
    "\n",
    "        Args:\n",
    "            net: trained model\n",
    "            include_bn: If include_bn, then gradients w.r.t. BN parameters and bias\n",
    "            values are also included. Otherwise only gradients with dim > 1 are considered.\n",
    "\n",
    "        Returns:\n",
    "            a concatenated numpy vector containing all gradients\n",
    "    \"\"\"\n",
    "    filter = lambda p: include_bn or len(p.data.size()) > 1\n",
    "    return np.concatenate([p.grad.data.cpu().numpy().ravel() for p in net.parameters() if filter(p)])\n",
    "\n",
    "\n",
    "################################################################################\n",
    "#                  For computing Hessian-vector products\n",
    "################################################################################\n",
    "def eval_hess_vec_prod(vec, params, net, criterion, dataloader, use_cuda=False):\n",
    "    \"\"\"\n",
    "    Evaluate product of the Hessian of the loss function with a direction vector \"vec\".\n",
    "    The product result is saved in the grad of net.\n",
    "\n",
    "    Args:\n",
    "        vec: a list of tensor with the same dimensions as \"params\".\n",
    "        params: the parameter list of the net (ignoring biases and BN parameters).\n",
    "        net: model with trained parameters.\n",
    "        criterion: loss function.\n",
    "        dataloader: dataloader for the dataset.\n",
    "        use_cuda: use GPU.\n",
    "    \"\"\"\n",
    "\n",
    "    if use_cuda:\n",
    "        net.cuda()\n",
    "        vec = [v.cuda() for v in vec]\n",
    "\n",
    "    net.eval()\n",
    "    net.zero_grad() # clears grad for every parameter in the net\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "        inputs, targets = Variable(inputs), Variable(targets)\n",
    "        if use_cuda:\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        grad_f = torch.autograd.grad(loss, inputs=params, create_graph=True)\n",
    "\n",
    "        # Compute inner product of gradient with the direction vector\n",
    "        prod = Variable(torch.zeros(1)).type(type(grad_f[0].data))\n",
    "        for (g, v) in zip(grad_f, vec):\n",
    "            prod = prod + (g * v).cpu().sum()\n",
    "\n",
    "        # Compute the Hessian-vector product, H*v\n",
    "        # prod.backward() computes dprod/dparams for every parameter in params and\n",
    "        # accumulate the gradients into the params.grad attributes\n",
    "        prod.backward()\n",
    "\n",
    "\n",
    "################################################################################\n",
    "#                  For computing Eigenvalues of Hessian\n",
    "################################################################################\n",
    "def min_max_hessian_eigs(net, dataloader, criterion, rank=0, use_cuda=False, verbose=False):\n",
    "    \"\"\"\n",
    "        Compute the largest and the smallest eigenvalues of the Hessian marix.\n",
    "\n",
    "        Args:\n",
    "            net: the trained model.\n",
    "            dataloader: dataloader for the dataset, may use a subset of it.\n",
    "            criterion: loss function.\n",
    "            rank: rank of the working node.\n",
    "            use_cuda: use GPU\n",
    "            verbose: print more information\n",
    "\n",
    "        Returns:\n",
    "            maxeig: max eigenvalue\n",
    "            mineig: min eigenvalue\n",
    "            hess_vec_prod.count: number of iterations for calculating max and min eigenvalues\n",
    "    \"\"\"\n",
    "\n",
    "    params = [p for p in net.parameters() if len(p.size()) > 1]\n",
    "    N = sum(p.numel() for p in params)\n",
    "\n",
    "    def hess_vec_prod(vec):\n",
    "        hess_vec_prod.count += 1  # simulates a static variable\n",
    "        vec = npvec_to_tensorlist(vec, params)\n",
    "        start_time = time.time()\n",
    "        eval_hess_vec_prod(vec, params, net, criterion, dataloader, use_cuda)\n",
    "        prod_time = time.time() - start_time\n",
    "        if verbose and rank == 0: print(\"   Iter: %d  time: %f\" % (hess_vec_prod.count, prod_time))\n",
    "        return gradtensor_to_npvec(net)\n",
    "\n",
    "    hess_vec_prod.count = 0\n",
    "    if verbose and rank == 0: print(\"Rank %d: computing max eigenvalue\" % rank)\n",
    "\n",
    "    A = LinearOperator((N, N), matvec=hess_vec_prod)\n",
    "    eigvals, eigvecs = eigsh(A, k=1, tol=1e-2)\n",
    "    maxeig = eigvals[0]\n",
    "    if verbose and rank == 0: print('max eigenvalue = %f' % maxeig)\n",
    "\n",
    "    # If the largest eigenvalue is positive, shift matrix so that any negative eigenvalue is now the largest\n",
    "    # We assume the smallest eigenvalue is zero or less, and so this shift is more than what we need\n",
    "    shift = maxeig*.51\n",
    "    def shifted_hess_vec_prod(vec):\n",
    "        return hess_vec_prod(vec) - shift*vec\n",
    "\n",
    "    if verbose and rank == 0: print(\"Rank %d: Computing shifted eigenvalue\" % rank)\n",
    "\n",
    "    A = LinearOperator((N, N), matvec=shifted_hess_vec_prod)\n",
    "    eigvals, eigvecs = eigsh(A, k=1, tol=1e-2)\n",
    "    eigvals = eigvals + shift\n",
    "    mineig = eigvals[0]\n",
    "    if verbose and rank == 0: print('min eigenvalue = ' + str(mineig))\n",
    "\n",
    "    if maxeig <= 0 and mineig > 0:\n",
    "        maxeig, mineig = mineig, maxeig\n",
    "\n",
    "    return maxeig, mineig, hess_vec_prod.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from tqdm.autonotebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from interpret.misc import get_state_dicts, normalize_direction, get_rand_dir, plot_loss_landscape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trained_none = train(hparams={'lr': 0.001, 'bs': 2}, n_runs=1, telemetry=False, max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trained_bn = train(nn.BatchNorm2d, hparams={'lr': 0.005, 'bs': 128}, n_runs=1, telemetry=False, max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessian_eigs(network, dataloader, loss_fn=nn.CrossEntropyLoss(), dir1=None, dir2=None,\n",
    "                   dir1_bound=(-1,1,20), dir2_bound=(-1,1,20), device=None):\n",
    "    device = ('cuda' if torch.cuda.is_available() else 'cpu') if device is None else device\n",
    "    trained_sd = copy.deepcopy(network.state_dict())\n",
    "\n",
    "    eigs = []\n",
    "    x_pts = dir1_bound[2]\n",
    "    y_pts = dir2_bound[2]\n",
    "    total = x_pts*y_pts\n",
    "    for sd in tqdm(get_state_dicts(trained_sd, dir1, dir2,\n",
    "                                   dir1_bound=dir1_bound, dir2_bound=dir2_bound),\n",
    "                   total=total, desc='Generating eigs'):\n",
    "        network.load_state_dict(sd)\n",
    "        maxeig,mineig,c = min_max_hessian_eigs(network, dataloader, loss_fn, use_cuda=torch.cuda.is_available())\n",
    "        print(maxeig, mineig)\n",
    "        eigs.append(abs(mineig/maxeig))\n",
    "\n",
    "    # Restore original state\n",
    "    network.load_state_dict(trained_sd)\n",
    "\n",
    "    X = np.linspace(*dir1_bound)\n",
    "    Y = np.linspace(*dir2_bound)\n",
    "    X,Y = np.meshgrid(X,Y)\n",
    "    Z = np.array(eigs).reshape((x_pts, y_pts)).T\n",
    "\n",
    "    return X,Y,Z\n",
    "\n",
    "def plot_eigs(out, title):\n",
    "    sns.set_style('white')\n",
    "    plt.figure(figsize=(12,10))\n",
    "    plt.imshow(out[2], cmap='viridis')\n",
    "    plt.clim(vmin=0,vmax=0.5)\n",
    "#     plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out = hessian_eigs(trained_bn, sub_val_dl, dir1_bound=(-1,1,16), dir2_bound=(-1,1,16))\n",
    "plot_eigs(out, 'BatchNorm Hessian Eigs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = hessian_eigs(trained_none, sub_val_dl, dir1_bound=(-1,1,16), dir2_bound=(-1,1,16))\n",
    "plot_eigs(out, 'No BatchNorm Hessian Eigs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLUFuncOverride:\n",
    "    def __init__(self):\n",
    "        self._orig_relu = F.relu\n",
    "        \n",
    "        def fn(*args, **kwargs):\n",
    "            self.i += 1\n",
    "            if self.i > self.iters:\n",
    "                F.relu = self._orig_relu\n",
    "            return GradReLU.apply(args[0])\n",
    "        \n",
    "        self.fn = fn\n",
    "        self.iters = 50\n",
    "        self.i = 0\n",
    "        \n",
    "    def __enter__(self):\n",
    "        F.relu = self.fn\n",
    "    def __exit__(self, *args):\n",
    "        F.relu = self._orig_relu\n",
    "        \n",
    "class GradReLU(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(self, x, inplace=False):\n",
    "        return x.clamp(min=0)\n",
    "    @staticmethod\n",
    "    def backward(self, grads):\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from interpret import OptVis, denorm, unfreeze\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import Image\n",
    "class VisList(pl.callbacks.base.Callback):\n",
    "    def __init__(self, layer, channel):\n",
    "        self.images = []\n",
    "        self.layer = layer\n",
    "        self.c = channel\n",
    "        \n",
    "    def on_batch_start(self, trainer, pl_module):\n",
    "        if getattr(self, 'images', None) is None: self.images = []\n",
    "        with ReLUFuncOverride():\n",
    "            v = OptVis.from_layer(pl_module, self.layer, self.c).vis(verbose=False, thresh=(200,))\n",
    "        self.images.append(denorm(v()))\n",
    "        unfreeze(pl_module.train())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = VisList('model/body/4', 33)\n",
    "net = train(nn.BatchNorm2d, {'lr': 1e-2, 'bs': 256}, n_runs=1, \n",
    "      callbacks=[vis], use_resnet=True, max_epochs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = vis.images\n",
    "name = 'vis-randinit-saved2.gif'\n",
    "images[0].save(name,\n",
    "               save_all=True, append_images=images[1:], \n",
    "               optimize=False, duration=200, loop=0)\n",
    "\n",
    "Image(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = vis.images\n",
    "name = 'vis-randinit3.gif'\n",
    "images[0].save(name,\n",
    "               save_all=True, append_images=images[1:], \n",
    "               optimize=False, duration=200, loop=0)\n",
    "\n",
    "Image(name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
